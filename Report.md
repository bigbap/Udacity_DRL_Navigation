# Report for Navigation - Deep RL NanoDegree P1 

The goal of this project is to build and train an agent that can solve Banana world.

The agent has to navigate an open world with yellow and blue banana's scattered around. A reward of 1 is given for walking over a yellow banana and -1 for walking over a blue one.

The world is solved once the agent has accumulated an average score of 13 over 100 episodes. An example of a trained agent can be seen below:

![trained agent](https://i.imgur.com/0JG7ud8.gif)

With the implementation that I will outline in this report, I was able to train an agent to solve Banana world in just [x] episodes.

## Implementation

Initially, I implemented a DQN with an experience replay buffer. Even though the agent could be trained to solve the problem, I decided to implement a DDQN and a PER buffer as well.

### DQN with Experience Replay

### DDQN with Experience Replay

### DQN with Prioritised Experience Replay

### DDQN with Prioritised Expereince Replay

### Neural Net

the 

## Plot of Rewards

## Ideas for the Future

- implement dueling DQN